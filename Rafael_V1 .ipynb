{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploading different packages- to remove the one we do not need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import LeaveOneOut,KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import LeaveOneOut,ShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from random import seed\n",
    "seed(123)\n",
    "rcParams['figure.figsize'] = 12, 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set path to imprt and save files from and in\n",
    "path = 'C:/Users/Yonathan/Desktop/Rafael'\n",
    "\n",
    "#upload data\n",
    "train = pd.read_csv(os.path.join(path,r'train.csv'),index_col='Unnamed: 0')\n",
    "test = pd.read_csv(os.path.join(path,r'test.csv'),index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove labels names from data\n",
    "train=train.drop('targetName', 1)\n",
    "#remove unnecessary time cells from data\n",
    "col_names = list(train)\n",
    "for name in col_names:\n",
    "    if name[:4] == \"Time\":\n",
    "        train=train.drop(name, 1)\n",
    "col_names = list(test)\n",
    "for name in col_names:\n",
    "    if name[:4] == \"Time\":\n",
    "        test=test.drop(name, 1)\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build a function vec_size which measures vector magnitude\n",
    "def vec_size(x,y,z):\n",
    "    return (np.sqrt(z**2+x**2+y**2))\n",
    "#create a df vel_mag with the magnitude of the velocity and val_mean which average the velocity of the samples(row)   \n",
    "def vel(data):    \n",
    "    vel_magn=pd.DataFrame(np.zeros(shape=(len(data),30)))\n",
    "    for i, j in zip(range(3,179,6), range(0,31)):\n",
    "        x = data.iloc[:,i]\n",
    "        y = data.iloc[:,i+1]\n",
    "        z = data.iloc[:,i+2]\n",
    "    #velocity magnitude matrix    \n",
    "        vel_magn.iloc[:,j] =vec_size(x,y,z)\n",
    "    return (vel_magn)\n",
    "\n",
    "vel_mag_train = vel(train)\n",
    "vel_mag_test = vel(test)\n",
    "#mean velocity magnitudevector\n",
    "vel_mean_train=np.mean(vel_mag_train, axis=1)\n",
    "vel_mean_test=np.mean(vel_mag_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a function to calculate the acceleration between each step\n",
    "def acc(data, vel_res):   \n",
    "    acc_df=pd.DataFrame(np.zeros(shape=(len(data),30)))\n",
    "    for i in range(0,29):\n",
    "        vel1=vel_res.iloc[:,i]\n",
    "        vel2=vel_res.iloc[:,i+1]\n",
    "        acc_df.iloc[:,i]=vel2-vel1\n",
    "    return (acc_df) \n",
    "\n",
    "acc_df_train =acc(train, vel_mag_train)\n",
    "acc_df_test =acc(test, vel_mag_test)\n",
    "#mean acc \n",
    "acc_mean_train=np.mean(acc_df_train, axis=1)\n",
    "acc_mean_test=np.mean(acc_df_test, axis=1)\n",
    "#print (acc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#angle calculation\n",
    "def calc_angle(n):\n",
    "        x_prev = train.iloc[:,n]\n",
    "        x_curr = train.iloc[:,n-6]\n",
    "        y_prev = train.iloc[:,n+1]\n",
    "        y_curr = train.iloc[:,n-5]\n",
    "        z_prev = train.iloc[:,n+2]\n",
    "        z_curr = train.iloc[:,n-4]\n",
    "        curr_point_vec = [x_curr-x_prev,y_curr-y_prev,z_curr-z_prev]\n",
    "        curr_point_vec_mag = vec_size(curr_point_vec[0],curr_point_vec[1],curr_point_vec[2])\n",
    "        curr_point_vec_norm = [curr_point_vec[0]/curr_point_vec_mag,curr_point_vec[1]/curr_point_vec_mag,curr_point_vec[2]/curr_point_vec_mag]\n",
    "        plain_vec =[x_curr-x_prev,y_curr-y_prev,0] \n",
    "        plain_vec_mag = vec_size(plain_vec[0],plain_vec[1],0)\n",
    "        plain_vec_norm = [plain_vec[0]/plain_vec_mag,plain_vec[1]/plain_vec_mag,0]\n",
    "        res = curr_point_vec_norm[0]*plain_vec_norm[0] +curr_point_vec_norm[1]*plain_vec_norm[1] +curr_point_vec_norm[2]* plain_vec_norm[2] \n",
    "        angle = np.arccos(res)\n",
    "        return (angle*180.0/ np.pi)\n",
    "    \n",
    "#run it on a whole df\n",
    "def angle(data):    \n",
    "    angle_df=pd.DataFrame(np.zeros(shape=(len(data),29)))\n",
    "    for i, j in zip(range(6,182,6), range(0,28)):\n",
    "        #print (train.iloc[:,i])\n",
    "        angle_df.iloc[:,j] =calc_angle(i)\n",
    "    return(angle_df)\n",
    "\n",
    "angle_df_train=angle(train)\n",
    "angle_df_test=angle(test)\n",
    "\n",
    "#calculate it mean\n",
    "angle_mean_train=np.mean(angle_df_train, axis=1)\n",
    "angle_mean_test=np.mean(angle_df_test, axis=1)\n",
    "#print (angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a df to calculate the change in angles between each step\n",
    "def angle_che(data,angle_df):\n",
    "    angle_change_df=pd.DataFrame(np.zeros(shape=(len(data),30)))\n",
    "    for i in range(0,28):\n",
    "        ang1=angle_df.iloc[:,i]\n",
    "        ang2=angle_df.iloc[:,i+1]\n",
    "        angle_change_df.iloc[:,i]=np.abs(ang2-ang1)\n",
    "        \n",
    "    return(angle_change_df)\n",
    "#print (angle_change_df)\n",
    "\n",
    "\n",
    "angle_change_df_train = angle_che(train,angle_df_train)\n",
    "angle_change_df_test = angle_che(test,angle_df_test)\n",
    "\n",
    "#calculate the mean\n",
    "angle_change_mean_train=np.mean(angle_change_df_train, axis=1)\n",
    "angle_change_mean_test=np.mean(angle_change_df_test, axis=1)\n",
    "#print (angle_change_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count how many time steps each samples has (as non NaN)\n",
    "def count_time(data):\n",
    "    time_vec=[]\n",
    "    for i in range(0,len(data)):\n",
    "        sample=data.iloc[i,:]\n",
    "        time_vec.append((29-sample.isnull().sum()/6)/2)\n",
    "    return (time_vec)\n",
    "time_epoch_train = pd.DataFrame(data=count_time(train))\n",
    "time_epoch_test = pd.DataFrame(data=count_time(test)) \n",
    "#time_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create new variable to store the data\n",
    "new_train =train.copy(deep=True)\n",
    "new_test =test.copy(deep=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove Position columns from data\n",
    "col_names=list(new_train)\n",
    "for name in col_names:\n",
    "    if str(name)[:1] == \"p\":\n",
    "        new_train=new_train.drop(name, 1)\n",
    "\n",
    "col_names=list(new_test)\n",
    "for name in col_names:\n",
    "    if  str(name)[:1] == \"p\":\n",
    "        new_test=new_test.drop(name, 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a vector of all the matrices and array which we which to add to the data\n",
    "\n",
    "df_add_vec_train=[new_train,vel_mag_train,\n",
    "                  vel_mean_train,acc_df_train,\n",
    "                  acc_mean_train,angle_df_train,\n",
    "                  angle_mean_train,angle_change_df_train,\n",
    "                  angle_change_mean_train,\n",
    "                  time_epoch_train]\n",
    "\n",
    "df_add_vec_test=[new_test,vel_mag_test,\n",
    "                  vel_mean_test,acc_df_test,\n",
    "                  acc_mean_test,angle_df_test,\n",
    "                  angle_mean_test,angle_change_df_test,\n",
    "                  angle_change_mean_test,\n",
    "                  time_epoch_test]\n",
    "\n",
    "#merge them to the data\n",
    "final_train = pd.concat(df_add_vec_train, axis=1)\n",
    "final_test = pd.concat(df_add_vec_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearenge the column name to enable modeling\n",
    "final_train.columns=list(final_train)[:91]+[i for i in range(1,125)]\n",
    "final_test.columns=list(final_train)[:90]+[i for i in range(1,125)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keep the clean data in CSV files\n",
    "final_train.to_csv(os.path.join(path,r'final_train_Rafael.csv'),header=True,index=True)\n",
    "final_test.to_csv(os.path.join(path,r'final_test_Rafael.csv'),header=True,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperatre training data into features and labels\n",
    "Y =pd.DataFrame(final_train['class'])\n",
    "X =final_train.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split data to training and testinf sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "y_train,y_test=np.ravel(y_train),np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# in case needed it is posible to add an intex to the data \n",
    "ind=list(range(0,28746))\n",
    "final_train=final_train.assign(Index = ind)\n",
    "#final_train\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.647541\ttest-merror:0.74523\n",
      "[1]\ttrain-merror:0.610624\ttest-merror:0.724676\n",
      "[2]\ttrain-merror:0.589906\ttest-merror:0.71287\n",
      "[3]\ttrain-merror:0.573862\ttest-merror:0.707389\n",
      "[4]\ttrain-merror:0.556519\ttest-merror:0.702962\n",
      "[5]\ttrain-merror:0.547484\ttest-merror:0.698429\n",
      "[6]\ttrain-merror:0.537307\ttest-merror:0.694213\n",
      "[7]\ttrain-merror:0.528636\ttest-merror:0.693159\n",
      "[8]\ttrain-merror:0.524222\ttest-merror:0.692737\n",
      "[9]\ttrain-merror:0.51768\ttest-merror:0.692\n",
      "[10]\ttrain-merror:0.512124\ttest-merror:0.691051\n",
      "[11]\ttrain-merror:0.50553\ttest-merror:0.688416\n",
      "[12]\ttrain-merror:0.49987\ttest-merror:0.687151\n",
      "[13]\ttrain-merror:0.492705\ttest-merror:0.686624\n",
      "[14]\ttrain-merror:0.485643\ttest-merror:0.685464\n",
      "[15]\ttrain-merror:0.480762\ttest-merror:0.684832\n",
      "[16]\ttrain-merror:0.474064\ttest-merror:0.684621\n",
      "[17]\ttrain-merror:0.470481\ttest-merror:0.682513\n",
      "[18]\ttrain-merror:0.465133\ttest-merror:0.683778\n",
      "[19]\ttrain-merror:0.459837\ttest-merror:0.683989\n",
      "[20]\ttrain-merror:0.453346\ttest-merror:0.682407\n",
      "[21]\ttrain-merror:0.449608\ttest-merror:0.680299\n",
      "[22]\ttrain-merror:0.444831\ttest-merror:0.679456\n",
      "[23]\ttrain-merror:0.440573\ttest-merror:0.677875\n",
      "[24]\ttrain-merror:0.435069\ttest-merror:0.677875\n",
      "[25]\ttrain-merror:0.430604\ttest-merror:0.676821\n",
      "[26]\ttrain-merror:0.423958\ttest-merror:0.676505\n",
      "[27]\ttrain-merror:0.419233\ttest-merror:0.676188\n",
      "[28]\ttrain-merror:0.414611\ttest-merror:0.676083\n",
      "[29]\ttrain-merror:0.411029\ttest-merror:0.674713\n",
      "[30]\ttrain-merror:0.407446\ttest-merror:0.674291\n",
      "[31]\ttrain-merror:0.403032\ttest-merror:0.672394\n",
      "[32]\ttrain-merror:0.398307\ttest-merror:0.673342\n",
      "[33]\ttrain-merror:0.393946\ttest-merror:0.673237\n",
      "[34]\ttrain-merror:0.389688\ttest-merror:0.67271\n",
      "[35]\ttrain-merror:0.384184\ttest-merror:0.671867\n",
      "[36]\ttrain-merror:0.379147\ttest-merror:0.671656\n",
      "[37]\ttrain-merror:0.374942\ttest-merror:0.671023\n",
      "[38]\ttrain-merror:0.37032\ttest-merror:0.67018\n",
      "[39]\ttrain-merror:0.365907\ttest-merror:0.670496\n",
      "[40]\ttrain-merror:0.360611\ttest-merror:0.670813\n",
      "[41]\ttrain-merror:0.356664\ttest-merror:0.671234\n",
      "[42]\ttrain-merror:0.351991\ttest-merror:0.670602\n",
      "[43]\ttrain-merror:0.347059\ttest-merror:0.67018\n",
      "[44]\ttrain-merror:0.343424\ttest-merror:0.669969\n",
      "[45]\ttrain-merror:0.338595\ttest-merror:0.669864\n",
      "[46]\ttrain-merror:0.333922\ttest-merror:0.669442\n",
      "[47]\ttrain-merror:0.329664\ttest-merror:0.669337\n",
      "[48]\ttrain-merror:0.32577\ttest-merror:0.669126\n",
      "[49]\ttrain-merror:0.320837\ttest-merror:0.669969\n",
      "[50]\ttrain-merror:0.316008\ttest-merror:0.669969\n",
      "[51]\ttrain-merror:0.311491\ttest-merror:0.669548\n",
      "[52]\ttrain-merror:0.305104\ttest-merror:0.669126\n",
      "[53]\ttrain-merror:0.300068\ttest-merror:0.668494\n",
      "[54]\ttrain-merror:0.295706\ttest-merror:0.669126\n",
      "[55]\ttrain-merror:0.29259\ttest-merror:0.668494\n",
      "[56]\ttrain-merror:0.286827\ttest-merror:0.668388\n",
      "[57]\ttrain-merror:0.281738\ttest-merror:0.66765\n",
      "[58]\ttrain-merror:0.278467\ttest-merror:0.669021\n",
      "[59]\ttrain-merror:0.274469\ttest-merror:0.669337\n",
      "[60]\ttrain-merror:0.26964\ttest-merror:0.668494\n",
      "[61]\ttrain-merror:0.265382\ttest-merror:0.668494\n",
      "[62]\ttrain-merror:0.261073\ttest-merror:0.66765\n",
      "[63]\ttrain-merror:0.258061\ttest-merror:0.66744\n",
      "[64]\ttrain-merror:0.252453\ttest-merror:0.667123\n",
      "[65]\ttrain-merror:0.24778\ttest-merror:0.666175\n",
      "[66]\ttrain-merror:0.245288\ttest-merror:0.665437\n",
      "[67]\ttrain-merror:0.242692\ttest-merror:0.665226\n",
      "[68]\ttrain-merror:0.239265\ttest-merror:0.665437\n",
      "[69]\ttrain-merror:0.235059\ttest-merror:0.667123\n",
      "[70]\ttrain-merror:0.230853\ttest-merror:0.666386\n",
      "[71]\ttrain-merror:0.226959\ttest-merror:0.667229\n",
      "[72]\ttrain-merror:0.222961\ttest-merror:0.666913\n",
      "[73]\ttrain-merror:0.221559\ttest-merror:0.666913\n",
      "[74]\ttrain-merror:0.21782\ttest-merror:0.668388\n",
      "[75]\ttrain-merror:0.21403\ttest-merror:0.667018\n",
      "[76]\ttrain-merror:0.211174\ttest-merror:0.667967\n",
      "[77]\ttrain-merror:0.207643\ttest-merror:0.667018\n",
      "[78]\ttrain-merror:0.205774\ttest-merror:0.667123\n",
      "[79]\ttrain-merror:0.202347\ttest-merror:0.666807\n",
      "[80]\ttrain-merror:0.197518\ttest-merror:0.66765\n",
      "[81]\ttrain-merror:0.194091\ttest-merror:0.66744\n",
      "[82]\ttrain-merror:0.188379\ttest-merror:0.666913\n",
      "[83]\ttrain-merror:0.185316\ttest-merror:0.666175\n",
      "[84]\ttrain-merror:0.181733\ttest-merror:0.665648\n",
      "[85]\ttrain-merror:0.177683\ttest-merror:0.665121\n",
      "[86]\ttrain-merror:0.174931\ttest-merror:0.664488\n",
      "[87]\ttrain-merror:0.170673\ttest-merror:0.665226\n",
      "[88]\ttrain-merror:0.168285\ttest-merror:0.665859\n",
      "[89]\ttrain-merror:0.163144\ttest-merror:0.666596\n",
      "[90]\ttrain-merror:0.160496\ttest-merror:0.666386\n",
      "[91]\ttrain-merror:0.157277\ttest-merror:0.665542\n",
      "[92]\ttrain-merror:0.153642\ttest-merror:0.66491\n",
      "[93]\ttrain-merror:0.150683\ttest-merror:0.663329\n",
      "[94]\ttrain-merror:0.14819\ttest-merror:0.663329\n",
      "[95]\ttrain-merror:0.145802\ttest-merror:0.66354\n",
      "[96]\ttrain-merror:0.143258\ttest-merror:0.662485\n",
      "[97]\ttrain-merror:0.140869\ttest-merror:0.662169\n",
      "[98]\ttrain-merror:0.137806\ttest-merror:0.66375\n",
      "[99]\ttrain-merror:0.13521\ttest-merror:0.662907\n",
      "[100]\ttrain-merror:0.13334\ttest-merror:0.662907\n",
      "[101]\ttrain-merror:0.131108\ttest-merror:0.662802\n",
      "[102]\ttrain-merror:0.127784\ttest-merror:0.662907\n",
      "[103]\ttrain-merror:0.125552\ttest-merror:0.662591\n",
      "[104]\ttrain-merror:0.123059\ttest-merror:0.664067\n",
      "[105]\ttrain-merror:0.121346\ttest-merror:0.664383\n",
      "[106]\ttrain-merror:0.119113\ttest-merror:0.663645\n",
      "[107]\ttrain-merror:0.116257\ttest-merror:0.663856\n",
      "[108]\ttrain-merror:0.114336\ttest-merror:0.664488\n",
      "[109]\ttrain-merror:0.111532\ttest-merror:0.664488\n",
      "[110]\ttrain-merror:0.110338\ttest-merror:0.664383\n",
      "[111]\ttrain-merror:0.108261\ttest-merror:0.665437\n",
      "[112]\ttrain-merror:0.105925\ttest-merror:0.665437\n",
      "[113]\ttrain-merror:0.10338\ttest-merror:0.665753\n",
      "[114]\ttrain-merror:0.100836\ttest-merror:0.664804\n",
      "[115]\ttrain-merror:0.099642\ttest-merror:0.66354\n",
      "[116]\ttrain-merror:0.099122\ttest-merror:0.664383\n",
      "[117]\ttrain-merror:0.096838\ttest-merror:0.665964\n",
      "[118]\ttrain-merror:0.095384\ttest-merror:0.66628\n",
      "[119]\ttrain-merror:0.093047\ttest-merror:0.666596\n",
      "[120]\ttrain-merror:0.09097\ttest-merror:0.667018\n",
      "[121]\ttrain-merror:0.089101\ttest-merror:0.666913\n",
      "[122]\ttrain-merror:0.087128\ttest-merror:0.667123\n",
      "[123]\ttrain-merror:0.084895\ttest-merror:0.666069\n",
      "[124]\ttrain-merror:0.083234\ttest-merror:0.666491\n",
      "[125]\ttrain-merror:0.081416\ttest-merror:0.666491\n",
      "[126]\ttrain-merror:0.079859\ttest-merror:0.66628\n",
      "[127]\ttrain-merror:0.077834\ttest-merror:0.665859\n",
      "[128]\ttrain-merror:0.076795\ttest-merror:0.666807\n",
      "[129]\ttrain-merror:0.076016\ttest-merror:0.667967\n",
      "[130]\ttrain-merror:0.07368\ttest-merror:0.667545\n",
      "[131]\ttrain-merror:0.071811\ttest-merror:0.668283\n",
      "[132]\ttrain-merror:0.070461\ttest-merror:0.669548\n",
      "[133]\ttrain-merror:0.069266\ttest-merror:0.667861\n",
      "[134]\ttrain-merror:0.06802\ttest-merror:0.667229\n",
      "[135]\ttrain-merror:0.066982\ttest-merror:0.667334\n",
      "[136]\ttrain-merror:0.065735\ttest-merror:0.668072\n",
      "[137]\ttrain-merror:0.064645\ttest-merror:0.668494\n",
      "[138]\ttrain-merror:0.063295\ttest-merror:0.667861\n",
      "[139]\ttrain-merror:0.06127\ttest-merror:0.668177\n",
      "[140]\ttrain-merror:0.060128\ttest-merror:0.668283\n",
      "[141]\ttrain-merror:0.059037\ttest-merror:0.66628\n",
      "[142]\ttrain-merror:0.057791\ttest-merror:0.666702\n",
      "[143]\ttrain-merror:0.056078\ttest-merror:0.667123\n",
      "[144]\ttrain-merror:0.054312\ttest-merror:0.667334\n",
      "[145]\ttrain-merror:0.053118\ttest-merror:0.66765\n",
      "[146]\ttrain-merror:0.051768\ttest-merror:0.66744\n",
      "[147]\ttrain-merror:0.051041\ttest-merror:0.667229\n",
      "[148]\ttrain-merror:0.049691\ttest-merror:0.667967\n",
      "[149]\ttrain-merror:0.048289\ttest-merror:0.667756\n",
      "[150]\ttrain-merror:0.047095\ttest-merror:0.667756\n",
      "[151]\ttrain-merror:0.046472\ttest-merror:0.668388\n",
      "[152]\ttrain-merror:0.045329\ttest-merror:0.668915\n",
      "[153]\ttrain-merror:0.04481\ttest-merror:0.669337\n",
      "[154]\ttrain-merror:0.044031\ttest-merror:0.668388\n",
      "[155]\ttrain-merror:0.04237\ttest-merror:0.668705\n",
      "[156]\ttrain-merror:0.040708\ttest-merror:0.668283\n",
      "[157]\ttrain-merror:0.040033\ttest-merror:0.668283\n",
      "[158]\ttrain-merror:0.03941\ttest-merror:0.668705\n",
      "[159]\ttrain-merror:0.038372\ttest-merror:0.668705\n",
      "[160]\ttrain-merror:0.037749\ttest-merror:0.669864\n",
      "[161]\ttrain-merror:0.037697\ttest-merror:0.668599\n",
      "[162]\ttrain-merror:0.036866\ttest-merror:0.668915\n",
      "[163]\ttrain-merror:0.035672\ttest-merror:0.667756\n",
      "[164]\ttrain-merror:0.034062\ttest-merror:0.668599\n",
      "[165]\ttrain-merror:0.033595\ttest-merror:0.668705\n",
      "[166]\ttrain-merror:0.033075\ttest-merror:0.669442\n",
      "[167]\ttrain-merror:0.031829\ttest-merror:0.66881\n",
      "[168]\ttrain-merror:0.031206\ttest-merror:0.669021\n",
      "[169]\ttrain-merror:0.030947\ttest-merror:0.669548\n",
      "[170]\ttrain-merror:0.0297\ttest-merror:0.670075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171]\ttrain-merror:0.029441\ttest-merror:0.669864\n",
      "[172]\ttrain-merror:0.029181\ttest-merror:0.669969\n",
      "[173]\ttrain-merror:0.028506\ttest-merror:0.668915\n",
      "[174]\ttrain-merror:0.027623\ttest-merror:0.669653\n",
      "[175]\ttrain-merror:0.026845\ttest-merror:0.669548\n",
      "[176]\ttrain-merror:0.026222\ttest-merror:0.669653\n",
      "[177]\ttrain-merror:0.025598\ttest-merror:0.669232\n",
      "[178]\ttrain-merror:0.024664\ttest-merror:0.668705\n",
      "[179]\ttrain-merror:0.024196\ttest-merror:0.669653\n",
      "[180]\ttrain-merror:0.02347\ttest-merror:0.669864\n",
      "[181]\ttrain-merror:0.023106\ttest-merror:0.669969\n",
      "[182]\ttrain-merror:0.022275\ttest-merror:0.669126\n",
      "[183]\ttrain-merror:0.021704\ttest-merror:0.669126\n",
      "[184]\ttrain-merror:0.021237\ttest-merror:0.669864\n",
      "[185]\ttrain-merror:0.020873\ttest-merror:0.670391\n",
      "[186]\ttrain-merror:0.020873\ttest-merror:0.670391\n",
      "[187]\ttrain-merror:0.020458\ttest-merror:0.671551\n",
      "[188]\ttrain-merror:0.020146\ttest-merror:0.671023\n",
      "[189]\ttrain-merror:0.019471\ttest-merror:0.670496\n",
      "[190]\ttrain-merror:0.018693\ttest-merror:0.671445\n",
      "[191]\ttrain-merror:0.018329\ttest-merror:0.670602\n",
      "[192]\ttrain-merror:0.018018\ttest-merror:0.670391\n",
      "[193]\ttrain-merror:0.017654\ttest-merror:0.670496\n",
      "[194]\ttrain-merror:0.017498\ttest-merror:0.670918\n",
      "[195]\ttrain-merror:0.017291\ttest-merror:0.670918\n",
      "[196]\ttrain-merror:0.016927\ttest-merror:0.669759\n",
      "[197]\ttrain-merror:0.016823\ttest-merror:0.671234\n",
      "[198]\ttrain-merror:0.016096\ttest-merror:0.671129\n",
      "[199]\ttrain-merror:0.015577\ttest-merror:0.670707\n",
      "[200]\ttrain-merror:0.015162\ttest-merror:0.672288\n",
      "[201]\ttrain-merror:0.014539\ttest-merror:0.672183\n",
      "[202]\ttrain-merror:0.014227\ttest-merror:0.670602\n",
      "[203]\ttrain-merror:0.014019\ttest-merror:0.670391\n",
      "[204]\ttrain-merror:0.013812\ttest-merror:0.668494\n",
      "[205]\ttrain-merror:0.013448\ttest-merror:0.669969\n",
      "[206]\ttrain-merror:0.012721\ttest-merror:0.669759\n",
      "[207]\ttrain-merror:0.012462\ttest-merror:0.669021\n",
      "[208]\ttrain-merror:0.012046\ttest-merror:0.669969\n",
      "[209]\ttrain-merror:0.011735\ttest-merror:0.670391\n",
      "[210]\ttrain-merror:0.011579\ttest-merror:0.67018\n",
      "[211]\ttrain-merror:0.011216\ttest-merror:0.66881\n",
      "[212]\ttrain-merror:0.011008\ttest-merror:0.669232\n",
      "[213]\ttrain-merror:0.010696\ttest-merror:0.669864\n",
      "[214]\ttrain-merror:0.010541\ttest-merror:0.67018\n",
      "[215]\ttrain-merror:0.010385\ttest-merror:0.669442\n",
      "[216]\ttrain-merror:0.010333\ttest-merror:0.669864\n",
      "[217]\ttrain-merror:0.009866\ttest-merror:0.671129\n",
      "[218]\ttrain-merror:0.009762\ttest-merror:0.670286\n",
      "[219]\ttrain-merror:0.009606\ttest-merror:0.670496\n",
      "[220]\ttrain-merror:0.009242\ttest-merror:0.670918\n",
      "[221]\ttrain-merror:0.008931\ttest-merror:0.669969\n",
      "[222]\ttrain-merror:0.008827\ttest-merror:0.670391\n",
      "[223]\ttrain-merror:0.008515\ttest-merror:0.670286\n",
      "[224]\ttrain-merror:0.00836\ttest-merror:0.67018\n",
      "[225]\ttrain-merror:0.008308\ttest-merror:0.671551\n",
      "[226]\ttrain-merror:0.008048\ttest-merror:0.671656\n",
      "[227]\ttrain-merror:0.007996\ttest-merror:0.671234\n",
      "[228]\ttrain-merror:0.007685\ttest-merror:0.671867\n",
      "[229]\ttrain-merror:0.007373\ttest-merror:0.671761\n",
      "[230]\ttrain-merror:0.007217\ttest-merror:0.672183\n",
      "[231]\ttrain-merror:0.007165\ttest-merror:0.671972\n",
      "[232]\ttrain-merror:0.007114\ttest-merror:0.671129\n",
      "[233]\ttrain-merror:0.006958\ttest-merror:0.670918\n",
      "[234]\ttrain-merror:0.006594\ttest-merror:0.672183\n",
      "[235]\ttrain-merror:0.006594\ttest-merror:0.671023\n",
      "[236]\ttrain-merror:0.006542\ttest-merror:0.669864\n",
      "[237]\ttrain-merror:0.006387\ttest-merror:0.67018\n",
      "[238]\ttrain-merror:0.006439\ttest-merror:0.670391\n",
      "[239]\ttrain-merror:0.00649\ttest-merror:0.669548\n",
      "[240]\ttrain-merror:0.006179\ttest-merror:0.670602\n",
      "[241]\ttrain-merror:0.006231\ttest-merror:0.670496\n",
      "[242]\ttrain-merror:0.005867\ttest-merror:0.669442\n",
      "[243]\ttrain-merror:0.005712\ttest-merror:0.669442\n",
      "[244]\ttrain-merror:0.005348\ttest-merror:0.669442\n",
      "[245]\ttrain-merror:0.005192\ttest-merror:0.669337\n",
      "[246]\ttrain-merror:0.005089\ttest-merror:0.67018\n",
      "[247]\ttrain-merror:0.004673\ttest-merror:0.671129\n",
      "[248]\ttrain-merror:0.004517\ttest-merror:0.670918\n",
      "[249]\ttrain-merror:0.004465\ttest-merror:0.67018\n",
      "[250]\ttrain-merror:0.004258\ttest-merror:0.669232\n",
      "[251]\ttrain-merror:0.004206\ttest-merror:0.669232\n",
      "[252]\ttrain-merror:0.003946\ttest-merror:0.66881\n",
      "[253]\ttrain-merror:0.003842\ttest-merror:0.669653\n",
      "[254]\ttrain-merror:0.003687\ttest-merror:0.669759\n",
      "[255]\ttrain-merror:0.003687\ttest-merror:0.670918\n",
      "[256]\ttrain-merror:0.00379\ttest-merror:0.672183\n",
      "[257]\ttrain-merror:0.003687\ttest-merror:0.671972\n",
      "[258]\ttrain-merror:0.003271\ttest-merror:0.670707\n",
      "[259]\ttrain-merror:0.003064\ttest-merror:0.67134\n",
      "[260]\ttrain-merror:0.003064\ttest-merror:0.670813\n",
      "[261]\ttrain-merror:0.003012\ttest-merror:0.671129\n",
      "[262]\ttrain-merror:0.003012\ttest-merror:0.670707\n",
      "[263]\ttrain-merror:0.003012\ttest-merror:0.671023\n",
      "[264]\ttrain-merror:0.003012\ttest-merror:0.670707\n",
      "[265]\ttrain-merror:0.00296\ttest-merror:0.670707\n",
      "[266]\ttrain-merror:0.002804\ttest-merror:0.670391\n",
      "[267]\ttrain-merror:0.002804\ttest-merror:0.670602\n",
      "[268]\ttrain-merror:0.002752\ttest-merror:0.670918\n",
      "[269]\ttrain-merror:0.002752\ttest-merror:0.670496\n",
      "[270]\ttrain-merror:0.002752\ttest-merror:0.670075\n",
      "[271]\ttrain-merror:0.002752\ttest-merror:0.670391\n",
      "[272]\ttrain-merror:0.0027\ttest-merror:0.669864\n",
      "[273]\ttrain-merror:0.002596\ttest-merror:0.670813\n",
      "[274]\ttrain-merror:0.002544\ttest-merror:0.671445\n",
      "[275]\ttrain-merror:0.002337\ttest-merror:0.670707\n",
      "[276]\ttrain-merror:0.002285\ttest-merror:0.670391\n",
      "[277]\ttrain-merror:0.002129\ttest-merror:0.668915\n",
      "[278]\ttrain-merror:0.002077\ttest-merror:0.669759\n",
      "[279]\ttrain-merror:0.001973\ttest-merror:0.67018\n",
      "[280]\ttrain-merror:0.002025\ttest-merror:0.67018\n",
      "[281]\ttrain-merror:0.001869\ttest-merror:0.670391\n",
      "[282]\ttrain-merror:0.001765\ttest-merror:0.671445\n",
      "[283]\ttrain-merror:0.001662\ttest-merror:0.671023\n",
      "[284]\ttrain-merror:0.001558\ttest-merror:0.670496\n",
      "[285]\ttrain-merror:0.001506\ttest-merror:0.67134\n",
      "[286]\ttrain-merror:0.001558\ttest-merror:0.671972\n",
      "[287]\ttrain-merror:0.001454\ttest-merror:0.67134\n",
      "[288]\ttrain-merror:0.00135\ttest-merror:0.670391\n",
      "[289]\ttrain-merror:0.001246\ttest-merror:0.670707\n",
      "[290]\ttrain-merror:0.001142\ttest-merror:0.670391\n",
      "[291]\ttrain-merror:0.001142\ttest-merror:0.671129\n",
      "[292]\ttrain-merror:0.001142\ttest-merror:0.671129\n",
      "[293]\ttrain-merror:0.001142\ttest-merror:0.670707\n",
      "[294]\ttrain-merror:0.00109\ttest-merror:0.670707\n",
      "[295]\ttrain-merror:0.001038\ttest-merror:0.670918\n",
      "[296]\ttrain-merror:0.000987\ttest-merror:0.670496\n",
      "[297]\ttrain-merror:0.000935\ttest-merror:0.670918\n",
      "[298]\ttrain-merror:0.000935\ttest-merror:0.669337\n",
      "[299]\ttrain-merror:0.000883\ttest-merror:0.669864\n",
      "[300]\ttrain-merror:0.000883\ttest-merror:0.669442\n",
      "[301]\ttrain-merror:0.000883\ttest-merror:0.669126\n",
      "[302]\ttrain-merror:0.000779\ttest-merror:0.668915\n",
      "[303]\ttrain-merror:0.000779\ttest-merror:0.668915\n",
      "[304]\ttrain-merror:0.000779\ttest-merror:0.669337\n",
      "[305]\ttrain-merror:0.000727\ttest-merror:0.669126\n",
      "[306]\ttrain-merror:0.000675\ttest-merror:0.669864\n",
      "[307]\ttrain-merror:0.000623\ttest-merror:0.669759\n",
      "[308]\ttrain-merror:0.000571\ttest-merror:0.669759\n",
      "[309]\ttrain-merror:0.000571\ttest-merror:0.669442\n",
      "[310]\ttrain-merror:0.000467\ttest-merror:0.669021\n",
      "[311]\ttrain-merror:0.000467\ttest-merror:0.669337\n",
      "[312]\ttrain-merror:0.000467\ttest-merror:0.669232\n",
      "[313]\ttrain-merror:0.000467\ttest-merror:0.669126\n",
      "[314]\ttrain-merror:0.000467\ttest-merror:0.669653\n",
      "[315]\ttrain-merror:0.000363\ttest-merror:0.669232\n",
      "[316]\ttrain-merror:0.000312\ttest-merror:0.669232\n",
      "[317]\ttrain-merror:0.000312\ttest-merror:0.668494\n",
      "[318]\ttrain-merror:0.000312\ttest-merror:0.669442\n",
      "[319]\ttrain-merror:0.000312\ttest-merror:0.668599\n",
      "[320]\ttrain-merror:0.00026\ttest-merror:0.668599\n",
      "[321]\ttrain-merror:0.00026\ttest-merror:0.66765\n",
      "[322]\ttrain-merror:0.00026\ttest-merror:0.667756\n",
      "[323]\ttrain-merror:0.00026\ttest-merror:0.669442\n",
      "[324]\ttrain-merror:0.00026\ttest-merror:0.670075\n",
      "[325]\ttrain-merror:0.00026\ttest-merror:0.669969\n",
      "[326]\ttrain-merror:0.00026\ttest-merror:0.670391\n",
      "[327]\ttrain-merror:0.00026\ttest-merror:0.670918\n",
      "[328]\ttrain-merror:0.00026\ttest-merror:0.670075\n",
      "[329]\ttrain-merror:0.00026\ttest-merror:0.669864\n",
      "[330]\ttrain-merror:0.00026\ttest-merror:0.669337\n",
      "[331]\ttrain-merror:0.00026\ttest-merror:0.669337\n",
      "[332]\ttrain-merror:0.00026\ttest-merror:0.668705\n",
      "[333]\ttrain-merror:0.00026\ttest-merror:0.668283\n",
      "[334]\ttrain-merror:0.00026\ttest-merror:0.668283\n",
      "[335]\ttrain-merror:0.00026\ttest-merror:0.669021\n",
      "[336]\ttrain-merror:0.00026\ttest-merror:0.667967\n",
      "[337]\ttrain-merror:0.00026\ttest-merror:0.66744\n",
      "[338]\ttrain-merror:0.00026\ttest-merror:0.667334\n",
      "[339]\ttrain-merror:0.00026\ttest-merror:0.668599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[340]\ttrain-merror:0.00026\ttest-merror:0.668388\n",
      "[341]\ttrain-merror:0.00026\ttest-merror:0.668494\n",
      "[342]\ttrain-merror:0.00026\ttest-merror:0.66881\n",
      "[343]\ttrain-merror:0.000208\ttest-merror:0.668494\n",
      "[344]\ttrain-merror:0.000208\ttest-merror:0.668494\n",
      "[345]\ttrain-merror:0.000208\ttest-merror:0.667545\n",
      "[346]\ttrain-merror:0.000156\ttest-merror:0.667229\n",
      "[347]\ttrain-merror:0.000156\ttest-merror:0.66744\n",
      "[348]\ttrain-merror:0.000208\ttest-merror:0.668177\n",
      "[349]\ttrain-merror:0.000208\ttest-merror:0.668177\n",
      "[350]\ttrain-merror:0.000208\ttest-merror:0.667229\n",
      "[351]\ttrain-merror:0.000208\ttest-merror:0.66765\n",
      "[352]\ttrain-merror:0.000104\ttest-merror:0.668072\n",
      "[353]\ttrain-merror:0.000104\ttest-merror:0.667861\n",
      "[354]\ttrain-merror:0.000104\ttest-merror:0.667229\n",
      "[355]\ttrain-merror:0.000104\ttest-merror:0.667967\n",
      "[356]\ttrain-merror:0.000104\ttest-merror:0.667229\n",
      "[357]\ttrain-merror:0.000104\ttest-merror:0.66765\n",
      "[358]\ttrain-merror:0.000104\ttest-merror:0.667545\n",
      "[359]\ttrain-merror:0.000104\ttest-merror:0.66765\n",
      "[360]\ttrain-merror:0.000104\ttest-merror:0.66628\n",
      "[361]\ttrain-merror:0.000104\ttest-merror:0.666702\n",
      "[362]\ttrain-merror:0.000104\ttest-merror:0.667229\n",
      "[363]\ttrain-merror:0.000104\ttest-merror:0.66744\n",
      "[364]\ttrain-merror:0.000104\ttest-merror:0.667334\n",
      "[365]\ttrain-merror:0.000104\ttest-merror:0.66744\n",
      "[366]\ttrain-merror:0.000104\ttest-merror:0.666702\n",
      "[367]\ttrain-merror:0.000104\ttest-merror:0.667018\n",
      "[368]\ttrain-merror:0.000104\ttest-merror:0.666913\n",
      "[369]\ttrain-merror:5.2e-05\ttest-merror:0.666491\n",
      "[370]\ttrain-merror:5.2e-05\ttest-merror:0.66744\n",
      "[371]\ttrain-merror:5.2e-05\ttest-merror:0.667545\n",
      "[372]\ttrain-merror:5.2e-05\ttest-merror:0.667967\n",
      "[373]\ttrain-merror:5.2e-05\ttest-merror:0.66744\n",
      "[374]\ttrain-merror:5.2e-05\ttest-merror:0.667123\n",
      "[375]\ttrain-merror:5.2e-05\ttest-merror:0.66628\n",
      "[376]\ttrain-merror:5.2e-05\ttest-merror:0.666702\n",
      "[377]\ttrain-merror:5.2e-05\ttest-merror:0.667967\n",
      "[378]\ttrain-merror:5.2e-05\ttest-merror:0.667123\n",
      "[379]\ttrain-merror:5.2e-05\ttest-merror:0.667334\n",
      "[380]\ttrain-merror:5.2e-05\ttest-merror:0.667018\n",
      "[381]\ttrain-merror:5.2e-05\ttest-merror:0.667229\n",
      "[382]\ttrain-merror:5.2e-05\ttest-merror:0.667018\n",
      "[383]\ttrain-merror:5.2e-05\ttest-merror:0.666386\n",
      "[384]\ttrain-merror:5.2e-05\ttest-merror:0.666491\n",
      "[385]\ttrain-merror:5.2e-05\ttest-merror:0.666491\n",
      "[386]\ttrain-merror:5.2e-05\ttest-merror:0.666702\n",
      "[387]\ttrain-merror:0\ttest-merror:0.667018\n",
      "[388]\ttrain-merror:0\ttest-merror:0.666702\n",
      "[389]\ttrain-merror:0\ttest-merror:0.667018\n",
      "[390]\ttrain-merror:0\ttest-merror:0.667229\n",
      "[391]\ttrain-merror:0\ttest-merror:0.666702\n",
      "[392]\ttrain-merror:0\ttest-merror:0.665964\n",
      "[393]\ttrain-merror:0\ttest-merror:0.666596\n",
      "[394]\ttrain-merror:0\ttest-merror:0.66628\n",
      "[395]\ttrain-merror:0\ttest-merror:0.666913\n",
      "[396]\ttrain-merror:0\ttest-merror:0.666386\n",
      "[397]\ttrain-merror:0\ttest-merror:0.666596\n",
      "[398]\ttrain-merror:0\ttest-merror:0.66744\n",
      "[399]\ttrain-merror:0\ttest-merror:0.668283\n",
      "[400]\ttrain-merror:0\ttest-merror:0.667861\n",
      "[401]\ttrain-merror:0\ttest-merror:0.667861\n",
      "[402]\ttrain-merror:0\ttest-merror:0.666386\n",
      "[403]\ttrain-merror:0\ttest-merror:0.667229\n",
      "[404]\ttrain-merror:0\ttest-merror:0.667229\n",
      "[405]\ttrain-merror:0\ttest-merror:0.668388\n",
      "[406]\ttrain-merror:0\ttest-merror:0.668072\n",
      "[407]\ttrain-merror:0\ttest-merror:0.667967\n",
      "[408]\ttrain-merror:0\ttest-merror:0.667756\n",
      "[409]\ttrain-merror:0\ttest-merror:0.66765\n",
      "[410]\ttrain-merror:0\ttest-merror:0.668388\n",
      "[411]\ttrain-merror:0\ttest-merror:0.668388\n",
      "[412]\ttrain-merror:0\ttest-merror:0.669021\n",
      "[413]\ttrain-merror:0\ttest-merror:0.668599\n",
      "[414]\ttrain-merror:0\ttest-merror:0.668599\n",
      "[415]\ttrain-merror:0\ttest-merror:0.668388\n",
      "[416]\ttrain-merror:0\ttest-merror:0.668177\n",
      "[417]\ttrain-merror:0\ttest-merror:0.667756\n",
      "[418]\ttrain-merror:0\ttest-merror:0.668494\n",
      "[419]\ttrain-merror:0\ttest-merror:0.669232\n",
      "[420]\ttrain-merror:0\ttest-merror:0.669337\n",
      "[421]\ttrain-merror:0\ttest-merror:0.669653\n",
      "[422]\ttrain-merror:0\ttest-merror:0.669759\n",
      "[423]\ttrain-merror:0\ttest-merror:0.669232\n",
      "[424]\ttrain-merror:0\ttest-merror:0.670496\n",
      "[425]\ttrain-merror:0\ttest-merror:0.670075\n",
      "[426]\ttrain-merror:0\ttest-merror:0.670286\n",
      "[427]\ttrain-merror:0\ttest-merror:0.670707\n",
      "[428]\ttrain-merror:0\ttest-merror:0.671023\n",
      "[429]\ttrain-merror:0\ttest-merror:0.670602\n",
      "[430]\ttrain-merror:0\ttest-merror:0.670813\n",
      "[431]\ttrain-merror:0\ttest-merror:0.670496\n",
      "[432]\ttrain-merror:0\ttest-merror:0.670075\n",
      "[433]\ttrain-merror:0\ttest-merror:0.669864\n",
      "[434]\ttrain-merror:0\ttest-merror:0.670391\n",
      "[435]\ttrain-merror:0\ttest-merror:0.670918\n",
      "[436]\ttrain-merror:0\ttest-merror:0.670075\n",
      "[437]\ttrain-merror:0\ttest-merror:0.669021\n",
      "[438]\ttrain-merror:0\ttest-merror:0.669653\n",
      "[439]\ttrain-merror:0\ttest-merror:0.66881\n",
      "[440]\ttrain-merror:0\ttest-merror:0.669021\n",
      "[441]\ttrain-merror:0\ttest-merror:0.669021\n",
      "[442]\ttrain-merror:0\ttest-merror:0.668915\n",
      "[443]\ttrain-merror:0\ttest-merror:0.668494\n",
      "[444]\ttrain-merror:0\ttest-merror:0.669232\n",
      "[445]\ttrain-merror:0\ttest-merror:0.669021\n",
      "[446]\ttrain-merror:0\ttest-merror:0.667967\n",
      "[447]\ttrain-merror:0\ttest-merror:0.668072\n",
      "[448]\ttrain-merror:0\ttest-merror:0.668072\n",
      "[449]\ttrain-merror:0\ttest-merror:0.668177\n",
      "[450]\ttrain-merror:0\ttest-merror:0.668283\n",
      "[451]\ttrain-merror:0\ttest-merror:0.668915\n",
      "[452]\ttrain-merror:0\ttest-merror:0.667967\n",
      "[453]\ttrain-merror:0\ttest-merror:0.668705\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-b6be243d1efa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mwatchlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mxg_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mxg_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mnum_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mbst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxg_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwatchlist\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;31m# get prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mxg_test\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 806\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# a very simple XGboost model\n",
    "xg_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label=y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = 26\n",
    "param['min_child_weight']=1\n",
    "param['gamma']=0\n",
    "param['subsample']=1\n",
    "param['scale_pos_weight']=1\n",
    "param['colsample_bytree']=1\n",
    "param['learning_rate'] =0.1\n",
    "param['n_estimators']=1000\n",
    "param['seed']=123\n",
    "\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 1000\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist )\n",
    "# get prediction\n",
    "pred = np.int_(bst.predict( xg_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 25.05%\n"
     ]
    }
   ],
   "source": [
    "#calculation\n",
    "f1 = f1_score(y_test, pred,average='macro')\n",
    "print(\"F1: %.2f%%\" % (f1 * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#A simple Gradient boosting model\n",
    "train_gbdt=final_train.replace([np.inf],[np.nan])\n",
    "train_gbdt.fillna(0,inplace=True)\n",
    "y_gbdt=pd.DataFrame(train_gbdt['class'])\n",
    "X_gbdt=train_gbdt.drop('class', axis=1)\n",
    "\n",
    "ss = ShuffleSplit(n_splits=5,random_state=123345,test_size=0.2)\n",
    "for train_index, test_index in ss.split(X_gbdt,np.ravel(y_gbdt)):\n",
    "    X_train , X_test = X_gbdt.loc[train_index,:] , X_gbdt.loc[test_index,:]\n",
    "    y_train , y_test = y_gbdt.loc[train_index] , y_gbdt.loc[test_index]\n",
    "\n",
    "gbdt = GradientBoostingClassifier(max_depth=5,subsample=0.8,n_estimators=30)\n",
    "gbdt.fit(X_train,y_train)\n",
    "pred = gbdt.predict(X_test)\n",
    "print (classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18,  2,  2, ..., 25,  8,  2])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  2,  6, ..., 22,  8,  9], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_results = model.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(os.path.join(path,r'Rafael_submission1.csv'),header=True,index=True, index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
