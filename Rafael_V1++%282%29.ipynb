{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uploading different packages- to remove the one we do not need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import LeaveOneOut,KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import LeaveOneOut,ShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from random import seed\n",
    "seed(123)\n",
    "rcParams['figure.figsize'] = 12, 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#set path to imprt and save files from and in\n",
    "with open('PATHS.json') as json_data:\n",
    "    paths = json.load(json_data)\n",
    "\n",
    "#upload data\n",
    "train = pd.read_csv(paths[\"TRAIN_PATH\"],index_col='Unnamed: 0')\n",
    "test = pd.read_csv(paths[\"TEST_PATH\"],index_col='Unnamed: 0')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set path to imprt and save files from and in\n",
    "path = 'C:/Users/Yonathan/Desktop/Rafael'\n",
    "\n",
    "#upload data\n",
    "train = pd.read_csv(os.path.join(path,r'train.csv'),index_col='Unnamed: 0')\n",
    "test = pd.read_csv(os.path.join(path,r'test.csv'),index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove labels names from data\n",
    "train=train.drop('targetName', 1)\n",
    "#remove unnecessary time cells from data\n",
    "col_names = list(train)\n",
    "for name in col_names:\n",
    "    if name[:4] == \"Time\":\n",
    "        train=train.drop(name, 1)\n",
    "        \n",
    "col_names = list(test)\n",
    "for name in col_names:\n",
    "    if name[:4] == \"Time\":\n",
    "        test=test.drop(name, 1)\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build a function vec_size which measures vector magnitude\n",
    "def vec_size(x,y,z):\n",
    "    return (np.sqrt(z**2+x**2+y**2))\n",
    "#create a df vel_mag with the magnitude of the velocity and val_mean which average the velocity of the samples(row)   \n",
    "def vel(data):    \n",
    "    vel_magn=pd.DataFrame(np.zeros(shape=(len(data),30)))\n",
    "    for i in range(30):\n",
    "        x = data[\"velX_\"+str(i)]\n",
    "        y = data[\"velY_\"+str(i)]\n",
    "        z = data[\"velZ_\"+str(i)]\n",
    "    #velocity magnitude matrix    \n",
    "        vel_magn[\"vel_magnitude_\"+str(i)] =vec_size(x,y,z)\n",
    "    return (vel_magn)\n",
    "\n",
    "vel_mag_train = vel(train)\n",
    "vel_mag_test = vel(test)\n",
    "#mean velocity magnitudevector\n",
    "vel_mean_train = pd.DataFrame(np.mean(vel_mag_train, axis=1),columns=[\"vel_mean\"])\n",
    "vel_mean_test= pd.DataFrame(np.mean(vel_mag_test, axis=1),columns=[\"vel_mean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to calculate the acceleration between each step\n",
    "def acc(data, vel_res):   \n",
    "    acc_df=pd.DataFrame(np.zeros(shape=(len(data),30)))\n",
    "    for i in range(0,29):\n",
    "        vel1=vel_res[\"vel_magnitude_\"+str(i)]\n",
    "        vel2=vel_res[\"vel_magnitude_\"+str(i+1)]\n",
    "        acc_df[\"accel_\"+str(i)]=vel2-vel1\n",
    "    return (acc_df) \n",
    "\n",
    "acc_df_train =acc(train, vel_mag_train)\n",
    "acc_df_test =acc(test, vel_mag_test)\n",
    "#mean acc \n",
    "acc_mean_train=pd.DataFrame(np.mean(acc_df_train, axis=1),columns=[\"acc_mean\"])\n",
    "acc_mean_test=pd.DataFrame(np.mean(acc_df_test, axis=1),columns=[\"acc_mean\"])\n",
    "#print (acc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#angle calculation\n",
    "def calc_angle(data,pos_index): \n",
    "        x_prev = data[\"posX_\"+str(pos_index)] \n",
    "        x_curr = data[\"posX_\"+str(pos_index+1)]\n",
    "        \n",
    "        y_prev = data[\"posY_\"+str(pos_index)] \n",
    "        y_curr = data[\"posY_\"+str(pos_index+1)]\n",
    "        \n",
    "        z_prev = data[\"posZ_\"+str(pos_index)] \n",
    "        z_curr = data[\"posZ_\"+str(pos_index+1)]\n",
    "        \n",
    "        curr_point_vec = [x_curr-x_prev,y_curr-y_prev,z_curr-z_prev]\n",
    "        curr_point_vec_mag = vec_size(curr_point_vec[0],curr_point_vec[1],curr_point_vec[2])\n",
    "        curr_point_vec_norm = [curr_point_vec[0]/curr_point_vec_mag,curr_point_vec[1]/curr_point_vec_mag,curr_point_vec[2]/curr_point_vec_mag]\n",
    "        \n",
    "        plain_vec =[x_curr-x_prev,y_curr-y_prev,0] \n",
    "        plain_vec_mag = vec_size(plain_vec[0],plain_vec[1],0)\n",
    "        \n",
    "        plain_vec_norm = [plain_vec[0]/plain_vec_mag,plain_vec[1]/plain_vec_mag,0]\n",
    "        res = curr_point_vec_norm[0]*plain_vec_norm[0] +curr_point_vec_norm[1]*plain_vec_norm[1] +curr_point_vec_norm[2]* plain_vec_norm[2] \n",
    "        angle = np.arccos(res)\n",
    "        return (angle*180.0/ np.pi)\n",
    "    \n",
    "#run it on a whole df\n",
    "def angle(data, num_of_func = 1):    \n",
    "    angle_df=pd.DataFrame(np.zeros(shape=(len(data),29)))\n",
    "    for i in range(29): #TODO: Why range only until 29?\n",
    "        #print (train.iloc[:,i])\n",
    "        if num_of_func==1:\n",
    "            angle_df[\"angle_\"+str(i)] =calc_angle(data,i)\n",
    "        else:\n",
    "            angle_df[\"angle_\"+str(i)] =calc_angle2(data,i)\n",
    "    return angle_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_df_train=angle(train,1)\n",
    "angle_df_test=angle(test,1)\n",
    "\n",
    "angle_df_train2 =angle(train,2)\n",
    "angle_df_test2 =angle(test,2)\n",
    "'''\n",
    "print(\"angle_df_train: \")\n",
    "print(angle_df_train.head())\n",
    "print(\"angle_df_train2: \")\n",
    "print(angle_df_train2.head())\n",
    "'''\n",
    "#calculate the mean\n",
    "angle_mean_train = pd.DataFrame(np.mean(angle_df_train, axis=1),columns=[\"angle_mean\"])\n",
    "angle_mean_test = pd.DataFrame(np.mean(angle_df_test, axis=1),columns=[\"angle_mean\"])\n",
    "#print (angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angle_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.617473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.736715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.936719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.818096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.163958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.849170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.463868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.376943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.389857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.195490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.871182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.573313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.502802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.604138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23.629693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29.450548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.656823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.933236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23.868869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.377315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>17.427906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.565830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.317327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16.066199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.338818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.296199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18.117961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.946536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.208369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.988538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28716</th>\n",
       "      <td>8.302592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28717</th>\n",
       "      <td>8.591227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28718</th>\n",
       "      <td>15.295574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28719</th>\n",
       "      <td>6.591665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28720</th>\n",
       "      <td>1.231328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28721</th>\n",
       "      <td>10.534947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28722</th>\n",
       "      <td>5.161797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28723</th>\n",
       "      <td>13.594326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28724</th>\n",
       "      <td>8.955700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28725</th>\n",
       "      <td>4.643886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28726</th>\n",
       "      <td>1.869682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28727</th>\n",
       "      <td>9.770373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28728</th>\n",
       "      <td>20.296169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28729</th>\n",
       "      <td>15.244534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28730</th>\n",
       "      <td>10.169145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28731</th>\n",
       "      <td>7.881929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28732</th>\n",
       "      <td>10.824815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28733</th>\n",
       "      <td>11.586486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28734</th>\n",
       "      <td>3.350667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28735</th>\n",
       "      <td>15.330878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28736</th>\n",
       "      <td>10.866701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28737</th>\n",
       "      <td>4.680437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28738</th>\n",
       "      <td>24.665978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28739</th>\n",
       "      <td>19.944515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28740</th>\n",
       "      <td>9.786135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28741</th>\n",
       "      <td>2.145797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28742</th>\n",
       "      <td>14.258686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28743</th>\n",
       "      <td>11.593108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28744</th>\n",
       "      <td>6.125625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28745</th>\n",
       "      <td>20.137023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28746 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       angle_mean\n",
       "0        8.617473\n",
       "1        2.736715\n",
       "2        2.936719\n",
       "3        1.818096\n",
       "4       18.163958\n",
       "5        3.849170\n",
       "6       11.463868\n",
       "7        6.376943\n",
       "8        6.389857\n",
       "9       14.195490\n",
       "10      14.871182\n",
       "11       0.573313\n",
       "12       5.502802\n",
       "13       4.604138\n",
       "14      23.629693\n",
       "15      29.450548\n",
       "16       4.656823\n",
       "17      13.933236\n",
       "18      23.868869\n",
       "19       9.377315\n",
       "20      17.427906\n",
       "21       5.565830\n",
       "22      11.317327\n",
       "23      16.066199\n",
       "24       7.338818\n",
       "25       1.296199\n",
       "26      18.117961\n",
       "27       2.946536\n",
       "28       5.208369\n",
       "29       2.988538\n",
       "...           ...\n",
       "28716    8.302592\n",
       "28717    8.591227\n",
       "28718   15.295574\n",
       "28719    6.591665\n",
       "28720    1.231328\n",
       "28721   10.534947\n",
       "28722    5.161797\n",
       "28723   13.594326\n",
       "28724    8.955700\n",
       "28725    4.643886\n",
       "28726    1.869682\n",
       "28727    9.770373\n",
       "28728   20.296169\n",
       "28729   15.244534\n",
       "28730   10.169145\n",
       "28731    7.881929\n",
       "28732   10.824815\n",
       "28733   11.586486\n",
       "28734    3.350667\n",
       "28735   15.330878\n",
       "28736   10.866701\n",
       "28737    4.680437\n",
       "28738   24.665978\n",
       "28739   19.944515\n",
       "28740    9.786135\n",
       "28741    2.145797\n",
       "28742   14.258686\n",
       "28743   11.593108\n",
       "28744    6.125625\n",
       "28745   20.137023\n",
       "\n",
       "[28746 rows x 1 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle_mean_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a df to calculate the change in angles between each step\n",
    "def angle_che(data,angle_df):\n",
    "    angle_change_df=pd.DataFrame(np.zeros(shape=(len(data),30)))\n",
    "    for i in range(0,28):\n",
    "        ang1=angle_df[\"angle_\"+str(i)]\n",
    "        ang2=angle_df[\"angle_\"+str(i+1)]\n",
    "        angle_change_df[\"angle_change_\"+str(i)]=np.abs(ang2-ang1)\n",
    "        \n",
    "    return(angle_change_df)\n",
    "#print (angle_change_df)\n",
    "\n",
    "\n",
    "angle_change_df_train = angle_che(train,angle_df_train)\n",
    "angle_change_df_test = angle_che(test,angle_df_test)\n",
    "\n",
    "#calculate the mean\n",
    "angle_change_mean_train = pd.DataFrame(np.mean(angle_change_df_train, axis=1),columns=[\"angle_change_mean\"])\n",
    "angle_change_mean_test = pd.DataFrame(np.mean(angle_change_df_test, axis=1),columns=[\"angle_change_mean\"])\n",
    "#print (angle_change_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count how many time steps each samples has (as non NaN)\n",
    "def count_time(data):\n",
    "    res = pd.DataFrame()\n",
    "    time_vec=[]\n",
    "    for i in range(0,len(data)):\n",
    "        sample=data.iloc[i,:]\n",
    "        time_vec.append((29-sample.isnull().sum()/6)/2)\n",
    "    res[\"time_count\"] = time_vec\n",
    "    return res\n",
    "time_epoch_train = count_time(train)\n",
    "time_epoch_test = count_time(test) \n",
    "#time_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_go_up_and_go_down(table):\n",
    "    up_and_down = pd.DataFrame()\n",
    "    goes_up = np.zeros(len(table))\n",
    "    goes_down = np.zeros(len(table))\n",
    "    for i in range(len(table)):\n",
    "        if(does_go_up(table.loc[i])):\n",
    "            goes_up[i] = 1\n",
    "        if(does_go_down(table.loc[i])):\n",
    "            goes_down[i] = 1\n",
    "\n",
    "    up_and_down[\"goes_up\"] = goes_up\n",
    "    up_and_down[\"goes_down\"] = goes_down\n",
    "    return up_and_down\n",
    "\n",
    "\n",
    "def does_go_up(row):\n",
    "    for i in range(30):\n",
    "        if(row[\"velZ_\"+str(i)] > 0):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def does_go_down(row):\n",
    "    for i in range(30):\n",
    "        if(row[\"velZ_\"+str(i)] < 0):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "#get parabula parameters\n",
    "def calc_S(row):\n",
    "    S = []\n",
    "    for i in range(30):\n",
    "        if(np.isnan(row[\"posX_\"+str(i)])):\n",
    "            break\n",
    "        S.append(((row[\"posX_\"+str(i)])**2 + (row[\"posY_\"+str(i)])**2)**0.5)\n",
    "    return S\n",
    "\n",
    "def calc_parabola_params(table):\n",
    "    res = pd.DataFrame()\n",
    "    params = np.array([[0 for i in range(len(table))] for j in range(3)])\n",
    "    for i in range(len(table)):\n",
    "        row = table.loc[i]\n",
    "        S = calc_S(row)\n",
    "        current_params = np.polyfit(S, [row[\"posZ_\"+str(i)] for i in range(len(S))],2)\n",
    "        cur_f = np.multiply(current_params[0],(np.power(S,2))) + np.multiply(S,current_params[1]) + current_params[2]\n",
    "        '''\n",
    "        if(i%1000 == 0):\n",
    "            plt.plot(S, [row[\"posZ_\"+str(i)] for i in range(len(S))])\n",
    "            plt.plot(S, cur_f)\n",
    "            plt.savefig(\"images/yair_\" + str(i) + \".png\")\n",
    "            plt.clf()\n",
    "            print(\"iteration \" + str(i))\n",
    "        '''\n",
    "        params[0][i], params[1][i], params[2][i] = current_params[0], current_params[1], current_params[2]\n",
    "        res[\"parabola_parameter_a\"] = params[0]\n",
    "        res[\"parabola_parameter_b\"] = params[1]\n",
    "        res[\"parabola_parameter_c\"] = params[2]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get goes_up and goes_down features:\n",
    "up_and_down = create_go_up_and_go_down(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get parbola parameters for each features\n",
    "parabola_params = calc_parabola_params(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create new variable to store the data\n",
    "new_train =train.copy(deep=True)\n",
    "new_test =test.copy(deep=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove Position columns from data\n",
    "col_names=list(new_train)\n",
    "for name in col_names:\n",
    "    if str(name)[:3] == \"pos\":\n",
    "        new_train=new_train.drop(name, 1)\n",
    "\n",
    "col_names=list(new_test)\n",
    "for name in col_names:\n",
    "    if  str(name)[:3] == \"pos\":\n",
    "        new_test=new_test.drop(name, 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a vector of all the matrices and array which we which to add to the data\n",
    "\n",
    "df_add_vec_train=[new_train,vel_mag_train,\n",
    "                  vel_mean_train,acc_df_train,\n",
    "                  acc_mean_train,angle_df_train,\n",
    "                  angle_mean_train,angle_change_df_train,\n",
    "                  angle_change_mean_train,\n",
    "                  time_epoch_train, up_and_down, parabola_params]\n",
    "\n",
    "df_add_vec_test=[new_test,vel_mag_test,\n",
    "                  vel_mean_test,acc_df_test,\n",
    "                  acc_mean_test,angle_df_test,\n",
    "                  angle_mean_test,angle_change_df_test,\n",
    "                  angle_change_mean_test,\n",
    "                  time_epoch_test]\n",
    "\n",
    "#merge them to the data\n",
    "final_train = pd.concat(df_add_vec_train, axis=1)\n",
    "final_test = pd.concat(df_add_vec_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep the clean data in CSV files\n",
    "final_train.to_csv(os.path.join(path,r'final_train_Rafael.csv'), na_rep='NaN',header=True,index=True)\n",
    "final_test.to_csv(os.path.join(path,r'final_test_Rafael.csv'), na_rep='NaN',header=True,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "#final_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'velX_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-44a0e0b12408>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m#new_test=new_test.drop(name, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdel_exZeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-89-44a0e0b12408>\u001b[0m in \u001b[0;36mdel_exZeros\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcol_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mname_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m    \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'velX_0' is not defined"
     ]
    }
   ],
   "source": [
    "def del_exZeros(data):\n",
    "    col_names=list(data)\n",
    "    for name in col_names:\n",
    "        name_eval=str(eval(name))\n",
    "        if    int(name_eval)<100 :\n",
    "            print (name)\n",
    "        else:\n",
    "            print (\"None\")\n",
    "        #new_test=new_test.drop(name, 1)\n",
    "        \n",
    "del_exZeros(final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#rearenge the column name to enable modeling\n",
    "final_train.columns=list(final_train)[:91]+[i for i in range(1,125)]\n",
    "final_test.columns=list(final_train)[:90]+[i for i in range(1,125)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seperatre training data into features and labels\n",
    "Y =pd.DataFrame(final_train['class'])\n",
    "X =final_train.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split data to training and testinf sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "y_train,y_test=np.ravel(y_train),np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# in case needed it is posible to add an intex to the data \n",
    "ind=list(range(0,28746))\n",
    "final_train=final_train.assign(Index = ind)\n",
    "#final_train\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000000002A318A0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\Y...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000000002A318A0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\Y...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 26, 13, 56, 37, 15992, tzinfo=datetime.timezone.utc), 'msg_id': '93B2FC18EF4A4BF28BDC848645A64789', 'msg_type': 'execute_request', 'session': 'CF391D4DF2F04E29809F8EFBEB53123A', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '93B2FC18EF4A4BF28BDC848645A64789', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'CF391D4DF2F04E29809F8EFBEB53123A']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 26, 13, 56, 37, 15992, tzinfo=datetime.timezone.utc), 'msg_id': '93B2FC18EF4A4BF28BDC848645A64789', 'msg_type': 'execute_request', 'session': 'CF391D4DF2F04E29809F8EFBEB53123A', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '93B2FC18EF4A4BF28BDC848645A64789', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'CF391D4DF2F04E29809F8EFBEB53123A'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 26, 13, 56, 37, 15992, tzinfo=datetime.timezone.utc), 'msg_id': '93B2FC18EF4A4BF28BDC848645A64789', 'msg_type': 'execute_request', 'session': 'CF391D4DF2F04E29809F8EFBEB53123A', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '93B2FC18EF4A4BF28BDC848645A64789', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.For object>], cell_name='<ipython-input-68-2974f718ea45>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 140a5dd8, execution_c..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000000001410FC90, file \"<ipython-input-68-2974f718ea45>\", line 27>\n        result = <ExecutionResult object at 140a5dd8, execution_c..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000000001410FC90, file \"<ipython-input-68-2974f718ea45>\", line 27>, result=<ExecutionResult object at 140a5dd8, execution_c..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000000001410FC90, file \"<ipython-input-68-2974f718ea45>\", line 27>\n        self.user_global_ns = {'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', '#uploading different packages- to remove the one...2, 4\\n\\n#from create_features import *\\n#import json', \"#set path to imprt and save files from and in\\npa...th.join(path,r'test.csv'),index_col='Unnamed: 0')\", '#remove labels names from data\\ntrain=train.drop(...e\":\\n        test=test.drop(name, 1)\\n#train.head()', '# build a function vec_size which measures vecto...is=1)\\nvel_mean_test=np.mean(vel_mag_test, axis=1)', '#a function to calculate the acceleration betwee...test=np.mean(acc_df_test, axis=1)\\n#print (acc_df)', '#angle calculation\\ndef calc_angle(data,pos_index...+str(i)] =calc_angle2(data,i)\\n    return angle_df', 'angle_df_train=angle(train,1)\\nangle_df_test=angl...=np.mean(angle_df_test, axis=1)\\n#print (angle_df)', '#a df to calculate the change in angles between ...hange_df_test, axis=1)\\n#print (angle_change_mean)', '#count how many time steps each samples has (as ...)\\ntime_epoch_test = count_time(test) \\n#time_epoch', '#get goes_up and goes_down features:\\nup_and_down = create_go_up_and_go_down(train)', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', \"#uploading different packages- to remove the one...size'] = 12, 4\\n\\nfrom create_features \\nimport json\", \"#uploading different packages- to remove the one...ze'] = 12, 4\\n\\nimport create_features \\nimport json\", '#uploading different packages- to remove the one...\\nfrom Rafael.create_features import *\\nimport json', 'def create_go_up_and_go_down(table):\\n    up_and_...parabola_parameter_c\"] = params[2]\\n    return res', '#get goes_up and goes_down features:\\nup_and_down = create_go_up_and_go_down(train)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LeaveOneOut': <class 'sklearn.model_selection._split.LeaveOneOut'>, 'Out': {33: 0                                               ...258.844718\n2     ...\nLength: 28747, dtype: object, 38: 0                                               ...258.844718\n2     ...\nLength: 28747, dtype: object, 53:                        velX_0    velY_0      vel...                NaN  \n\n[28750 rows x 336 columns], 54: 0                                               ...2.736715\n2       ...\nLength: 28747, dtype: object, 61:        angle_mean\n0        8.617473\n1        2.7...25625\n28745   20.137023\n\n[28746 rows x 1 columns], 64:            velX_0    velY_0      velZ_0      vel...               6425  \n\n[28746 rows x 336 columns]}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'ShuffleSplit': <class 'sklearn.model_selection._split.ShuffleSplit'>, 'StratifiedKFold': <class 'sklearn.cross_validation.StratifiedKFold'>, ...}\n        self.user_ns = {'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', '#uploading different packages- to remove the one...2, 4\\n\\n#from create_features import *\\n#import json', \"#set path to imprt and save files from and in\\npa...th.join(path,r'test.csv'),index_col='Unnamed: 0')\", '#remove labels names from data\\ntrain=train.drop(...e\":\\n        test=test.drop(name, 1)\\n#train.head()', '# build a function vec_size which measures vecto...is=1)\\nvel_mean_test=np.mean(vel_mag_test, axis=1)', '#a function to calculate the acceleration betwee...test=np.mean(acc_df_test, axis=1)\\n#print (acc_df)', '#angle calculation\\ndef calc_angle(data,pos_index...+str(i)] =calc_angle2(data,i)\\n    return angle_df', 'angle_df_train=angle(train,1)\\nangle_df_test=angl...=np.mean(angle_df_test, axis=1)\\n#print (angle_df)', '#a df to calculate the change in angles between ...hange_df_test, axis=1)\\n#print (angle_change_mean)', '#count how many time steps each samples has (as ...)\\ntime_epoch_test = count_time(test) \\n#time_epoch', '#get goes_up and goes_down features:\\nup_and_down = create_go_up_and_go_down(train)', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', \"#uploading different packages- to remove the one...size'] = 12, 4\\n\\nfrom create_features \\nimport json\", \"#uploading different packages- to remove the one...ze'] = 12, 4\\n\\nimport create_features \\nimport json\", '#uploading different packages- to remove the one...\\nfrom Rafael.create_features import *\\nimport json', 'def create_go_up_and_go_down(table):\\n    up_and_...parabola_parameter_c\"] = params[2]\\n    return res', '#get goes_up and goes_down features:\\nup_and_down = create_go_up_and_go_down(train)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LeaveOneOut': <class 'sklearn.model_selection._split.LeaveOneOut'>, 'Out': {33: 0                                               ...258.844718\n2     ...\nLength: 28747, dtype: object, 38: 0                                               ...258.844718\n2     ...\nLength: 28747, dtype: object, 53:                        velX_0    velY_0      vel...                NaN  \n\n[28750 rows x 336 columns], 54: 0                                               ...2.736715\n2       ...\nLength: 28747, dtype: object, 61:        angle_mean\n0        8.617473\n1        2.7...25625\n28745   20.137023\n\n[28746 rows x 1 columns], 64:            velX_0    velY_0      velZ_0      vel...               6425  \n\n[28746 rows x 336 columns]}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'ShuffleSplit': <class 'sklearn.model_selection._split.ShuffleSplit'>, 'StratifiedKFold': <class 'sklearn.cross_validation.StratifiedKFold'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Yonathan\\<ipython-input-68-2974f718ea45> in <module>()\n     22 clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n     23                    cv=StratifiedKFold(y_train,n_folds=5, shuffle=True), \n     24                    scoring='f1_macro',\n     25                    verbose=10, refit=True)\n     26 \n---> 27 clf.fit(X_train, y_train)\n     28 \n     29 #trust your CV!\n     30 best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n     31 print('F1 score:', score)\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=sklearn.cross_validation.Stratif...obs', refit=True, scoring='f1_macro', verbose=10), X=           velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], y=array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64))\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...bs', refit=True, scoring='f1_macro', verbose=10)>\n        X =            velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns]\n        y = array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64)\n        self.param_grid = {'colsample_bytree': [0.7], 'learning_rate': [0.05], 'max_depth': [6], 'min_child_weight': [11], 'n_estimators': [5], 'nthread': [4], 'objective': ['multi:softmax'], 'seed': [1337], 'silent': [1], 'subsample': [0.8]}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=sklearn.cross_validation.Stratif...obs', refit=True, scoring='f1_macro', verbose=10), X=           velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], y=array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=5), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=5)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Oct 26 16:56:43 2017\nPID: 10132             Python 3.6.1: C:\\Users\\Yonathan\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8),            velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), make_scorer(f1_score, pos_label=None, average=macro), array([    0,     1,     2, ..., 19256, 19257, 19258]), array([   14,    16,    18, ..., 19244, 19245, 19249]), 10, {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 5, 'nthread': 4, 'objective': 'multi:softmax', 'seed': 1337, 'silent': 1, 'subsample': 0.8}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8),            velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), make_scorer(f1_score, pos_label=None, average=macro), array([    0,     1,     2, ..., 19256, 19257, 19258]), array([   14,    16,    18, ..., 19244, 19245, 19249]), 10, {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 5, 'nthread': 4, 'objective': 'multi:softmax', 'seed': 1337, 'silent': 1, 'subsample': 0.8}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8), X=           velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], y=array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), scorer=make_scorer(f1_score, pos_label=None, average=macro), train=array([    0,     1,     2, ..., 19256, 19257, 19258]), test=array([   14,    16,    18, ..., 19244, 19245, 19249]), verbose=10, parameters={'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 5, 'nthread': 4, 'objective': 'multi:softmax', 'seed': 1337, 'silent': 1, 'subsample': 0.8}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...os_weight=1, seed=1337, silent=1, subsample=0.8)>\n        X_train =            velX_0    velY_0      velZ_0      vel...               2631  \n\n[15399 rows x 335 columns]\n        y_train = array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64)\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py in fit(self=XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8), X=           velX_0    velY_0      velZ_0      vel...               2631  \n\n[15399 rows x 335 columns], y=array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)\n    434         if sample_weight is not None:\n    435             train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n    436                                     missing=self.missing)\n    437         else:\n    438             train_dmatrix = DMatrix(X, label=training_labels,\n--> 439                                     missing=self.missing)\n        self.missing = nan\n    440 \n    441         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n    442                               evals=evals,\n    443                               early_stopping_rounds=early_stopping_rounds,\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in __init__(self=<xgboost.core.DMatrix object>, data=array([[  3.17416735e+02,  -2.45790805e+00,  -7....000000e+00,   0.00000000e+00,   2.63100000e+03]]), label=array([ 2,  0, 11, ..., 20, 23,  0], dtype=int64), missing=nan, weight=None, silent=False, feature_names=['velX_0', 'velY_0', 'velZ_0', 'velX_1', 'velY_1', 'velZ_1', 'velX_2', 'velY_2', 'velZ_2', 'velX_3', 'velY_3', 'velZ_3', 'velX_4', 'velY_4', 'velZ_4', 'velX_5', 'velY_5', 'velZ_5', 'velX_6', 'velY_6', ...], feature_types=['float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', ...])\n    275         if label is not None:\n    276             self.set_label(label)\n    277         if weight is not None:\n    278             self.set_weight(weight)\n    279 \n--> 280         self.feature_names = feature_names\n        self.feature_names = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', ...]\n        feature_names = ['velX_0', 'velY_0', 'velZ_0', 'velX_1', 'velY_1', 'velZ_1', 'velX_2', 'velY_2', 'velZ_2', 'velX_3', 'velY_3', 'velZ_3', 'velX_4', 'velY_4', 'velZ_4', 'velX_5', 'velY_5', 'velZ_5', 'velX_6', 'velY_6', ...]\n    281         self.feature_types = feature_types\n    282 \n    283     def _init_from_csr(self, csr):\n    284         \"\"\"\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in feature_names(self=<xgboost.core.DMatrix object>, feature_names=['velX_0', 'velY_0', 'velZ_0', 'velX_1', 'velY_1', 'velZ_1', 'velX_2', 'velY_2', 'velZ_2', 'velX_3', 'velY_3', 'velZ_3', 'velX_4', 'velY_4', 'velZ_4', 'velX_5', 'velY_5', 'velZ_5', 'velX_6', 'velY_6', ...])\n    566         if feature_names is not None:\n    567             # validate feature name\n    568             if not isinstance(feature_names, list):\n    569                 feature_names = list(feature_names)\n    570             if len(feature_names) != len(set(feature_names)):\n--> 571                 raise ValueError('feature_names must be unique')\n    572             if len(feature_names) != self.num_col():\n    573                 msg = 'feature_names must have the same length as data'\n    574                 raise ValueError(msg)\n    575             # prohibit to use symbols may affect to parse. e.g. []<\n\nValueError: feature_names must be unique\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\", line 1665, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 439, in fit\n    missing=self.missing)\n  File \"C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 280, in __init__\n    self.feature_names = feature_names\n  File \"C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 571, in feature_names\n    raise ValueError('feature_names must be unique')\nValueError: feature_names must be unique\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Yonathan\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Oct 26 16:56:43 2017\nPID: 10132             Python 3.6.1: C:\\Users\\Yonathan\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8),            velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), make_scorer(f1_score, pos_label=None, average=macro), array([    0,     1,     2, ..., 19256, 19257, 19258]), array([   14,    16,    18, ..., 19244, 19245, 19249]), 10, {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 5, 'nthread': 4, 'objective': 'multi:softmax', 'seed': 1337, 'silent': 1, 'subsample': 0.8}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8),            velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), make_scorer(f1_score, pos_label=None, average=macro), array([    0,     1,     2, ..., 19256, 19257, 19258]), array([   14,    16,    18, ..., 19244, 19245, 19249]), 10, {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 5, 'nthread': 4, 'objective': 'multi:softmax', 'seed': 1337, 'silent': 1, 'subsample': 0.8}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8), X=           velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], y=array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), scorer=make_scorer(f1_score, pos_label=None, average=macro), train=array([    0,     1,     2, ..., 19256, 19257, 19258]), test=array([   14,    16,    18, ..., 19244, 19245, 19249]), verbose=10, parameters={'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 5, 'nthread': 4, 'objective': 'multi:softmax', 'seed': 1337, 'silent': 1, 'subsample': 0.8}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...os_weight=1, seed=1337, silent=1, subsample=0.8)>\n        X_train =            velX_0    velY_0      velZ_0      vel...               2631  \n\n[15399 rows x 335 columns]\n        y_train = array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64)\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py in fit(self=XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8), X=           velX_0    velY_0      velZ_0      vel...               2631  \n\n[15399 rows x 335 columns], y=array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)\n    434         if sample_weight is not None:\n    435             train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n    436                                     missing=self.missing)\n    437         else:\n    438             train_dmatrix = DMatrix(X, label=training_labels,\n--> 439                                     missing=self.missing)\n        self.missing = nan\n    440 \n    441         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n    442                               evals=evals,\n    443                               early_stopping_rounds=early_stopping_rounds,\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in __init__(self=<xgboost.core.DMatrix object>, data=array([[  3.17416735e+02,  -2.45790805e+00,  -7....000000e+00,   0.00000000e+00,   2.63100000e+03]]), label=array([ 2,  0, 11, ..., 20, 23,  0], dtype=int64), missing=nan, weight=None, silent=False, feature_names=['velX_0', 'velY_0', 'velZ_0', 'velX_1', 'velY_1', 'velZ_1', 'velX_2', 'velY_2', 'velZ_2', 'velX_3', 'velY_3', 'velZ_3', 'velX_4', 'velY_4', 'velZ_4', 'velX_5', 'velY_5', 'velZ_5', 'velX_6', 'velY_6', ...], feature_types=['float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', ...])\n    275         if label is not None:\n    276             self.set_label(label)\n    277         if weight is not None:\n    278             self.set_weight(weight)\n    279 \n--> 280         self.feature_names = feature_names\n        self.feature_names = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', ...]\n        feature_names = ['velX_0', 'velY_0', 'velZ_0', 'velX_1', 'velY_1', 'velZ_1', 'velX_2', 'velY_2', 'velZ_2', 'velX_3', 'velY_3', 'velZ_3', 'velX_4', 'velY_4', 'velZ_4', 'velX_5', 'velY_5', 'velZ_5', 'velX_6', 'velY_6', ...]\n    281         self.feature_types = feature_types\n    282 \n    283     def _init_from_csr(self, csr):\n    284         \"\"\"\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in feature_names(self=<xgboost.core.DMatrix object>, feature_names=['velX_0', 'velY_0', 'velZ_0', 'velX_1', 'velY_1', 'velZ_1', 'velX_2', 'velY_2', 'velZ_2', 'velX_3', 'velY_3', 'velZ_3', 'velX_4', 'velY_4', 'velZ_4', 'velX_5', 'velY_5', 'velZ_5', 'velX_6', 'velY_6', ...])\n    566         if feature_names is not None:\n    567             # validate feature name\n    568             if not isinstance(feature_names, list):\n    569                 feature_names = list(feature_names)\n    570             if len(feature_names) != len(set(feature_names)):\n--> 571                 raise ValueError('feature_names must be unique')\n    572             if len(feature_names) != self.num_col():\n    573                 msg = 'feature_names must have the same length as data'\n    574                 raise ValueError(msg)\n    575             # prohibit to use symbols may affect to parse. e.g. []<\n\nValueError: feature_names must be unique\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'timeout'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Yonathan\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Oct 26 16:56:43 2017\nPID: 10132             Python 3.6.1: C:\\Users\\Yonathan\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8),            velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), make_scorer(f1_score, pos_label=None, average=macro), array([    0,     1,     2, ..., 19256, 19257, 19258]), array([   14,    16,    18, ..., 19244, 19245, 19249]), 10, {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 5, 'nthread': 4, 'objective': 'multi:softmax', 'seed': 1337, 'silent': 1, 'subsample': 0.8}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8),            velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), make_scorer(f1_score, pos_label=None, average=macro), array([    0,     1,     2, ..., 19256, 19257, 19258]), array([   14,    16,    18, ..., 19244, 19245, 19249]), 10, {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 5, 'nthread': 4, 'objective': 'multi:softmax', 'seed': 1337, 'silent': 1, 'subsample': 0.8}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8), X=           velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], y=array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), scorer=make_scorer(f1_score, pos_label=None, average=macro), train=array([    0,     1,     2, ..., 19256, 19257, 19258]), test=array([   14,    16,    18, ..., 19244, 19245, 19249]), verbose=10, parameters={'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 5, 'nthread': 4, 'objective': 'multi:softmax', 'seed': 1337, 'silent': 1, 'subsample': 0.8}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...os_weight=1, seed=1337, silent=1, subsample=0.8)>\n        X_train =            velX_0    velY_0      velZ_0      vel...               2631  \n\n[15399 rows x 335 columns]\n        y_train = array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64)\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py in fit(self=XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8), X=           velX_0    velY_0      velZ_0      vel...               2631  \n\n[15399 rows x 335 columns], y=array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)\n    434         if sample_weight is not None:\n    435             train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n    436                                     missing=self.missing)\n    437         else:\n    438             train_dmatrix = DMatrix(X, label=training_labels,\n--> 439                                     missing=self.missing)\n        self.missing = nan\n    440 \n    441         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n    442                               evals=evals,\n    443                               early_stopping_rounds=early_stopping_rounds,\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in __init__(self=<xgboost.core.DMatrix object>, data=array([[  3.17416735e+02,  -2.45790805e+00,  -7....000000e+00,   0.00000000e+00,   2.63100000e+03]]), label=array([ 2,  0, 11, ..., 20, 23,  0], dtype=int64), missing=nan, weight=None, silent=False, feature_names=['velX_0', 'velY_0', 'velZ_0', 'velX_1', 'velY_1', 'velZ_1', 'velX_2', 'velY_2', 'velZ_2', 'velX_3', 'velY_3', 'velZ_3', 'velX_4', 'velY_4', 'velZ_4', 'velX_5', 'velY_5', 'velZ_5', 'velX_6', 'velY_6', ...], feature_types=['float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', ...])\n    275         if label is not None:\n    276             self.set_label(label)\n    277         if weight is not None:\n    278             self.set_weight(weight)\n    279 \n--> 280         self.feature_names = feature_names\n        self.feature_names = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', ...]\n        feature_names = ['velX_0', 'velY_0', 'velZ_0', 'velX_1', 'velY_1', 'velZ_1', 'velX_2', 'velY_2', 'velZ_2', 'velX_3', 'velY_3', 'velZ_3', 'velX_4', 'velY_4', 'velZ_4', 'velX_5', 'velY_5', 'velZ_5', 'velX_6', 'velY_6', ...]\n    281         self.feature_types = feature_types\n    282 \n    283     def _init_from_csr(self, csr):\n    284         \"\"\"\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in feature_names(self=<xgboost.core.DMatrix object>, feature_names=['velX_0', 'velY_0', 'velZ_0', 'velX_1', 'velY_1', 'velZ_1', 'velX_2', 'velY_2', 'velZ_2', 'velX_3', 'velY_3', 'velZ_3', 'velX_4', 'velY_4', 'velZ_4', 'velX_5', 'velY_5', 'velZ_5', 'velX_6', 'velY_6', ...])\n    566         if feature_names is not None:\n    567             # validate feature name\n    568             if not isinstance(feature_names, list):\n    569                 feature_names = list(feature_names)\n    570             if len(feature_names) != len(set(feature_names)):\n--> 571                 raise ValueError('feature_names must be unique')\n    572             if len(feature_names) != self.num_col():\n    573                 msg = 'feature_names must have the same length as data'\n    574                 raise ValueError(msg)\n    575             # prohibit to use symbols may affect to parse. e.g. []<\n\nValueError: feature_names must be unique\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-2974f718ea45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m                    verbose=10, refit=True)\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#trust your CV!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m         \"\"\"\n\u001b[1;32m--> 829\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    571\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 573\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m                 for train, test in cv)\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000000002A318A0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\Y...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000000002A318A0, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\Y...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 26, 13, 56, 37, 15992, tzinfo=datetime.timezone.utc), 'msg_id': '93B2FC18EF4A4BF28BDC848645A64789', 'msg_type': 'execute_request', 'session': 'CF391D4DF2F04E29809F8EFBEB53123A', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '93B2FC18EF4A4BF28BDC848645A64789', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'CF391D4DF2F04E29809F8EFBEB53123A']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 26, 13, 56, 37, 15992, tzinfo=datetime.timezone.utc), 'msg_id': '93B2FC18EF4A4BF28BDC848645A64789', 'msg_type': 'execute_request', 'session': 'CF391D4DF2F04E29809F8EFBEB53123A', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '93B2FC18EF4A4BF28BDC848645A64789', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'CF391D4DF2F04E29809F8EFBEB53123A'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 26, 13, 56, 37, 15992, tzinfo=datetime.timezone.utc), 'msg_id': '93B2FC18EF4A4BF28BDC848645A64789', 'msg_type': 'execute_request', 'session': 'CF391D4DF2F04E29809F8EFBEB53123A', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '93B2FC18EF4A4BF28BDC848645A64789', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='xgb_model = xgb.XGBClassifier()\\n\\n#brute force sc... %r\" % (param_name, best_parameters[param_name]))', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.For object>], cell_name='<ipython-input-68-2974f718ea45>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 140a5dd8, execution_c..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000000001410FC90, file \"<ipython-input-68-2974f718ea45>\", line 27>\n        result = <ExecutionResult object at 140a5dd8, execution_c..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000000001410FC90, file \"<ipython-input-68-2974f718ea45>\", line 27>, result=<ExecutionResult object at 140a5dd8, execution_c..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000000001410FC90, file \"<ipython-input-68-2974f718ea45>\", line 27>\n        self.user_global_ns = {'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', '#uploading different packages- to remove the one...2, 4\\n\\n#from create_features import *\\n#import json', \"#set path to imprt and save files from and in\\npa...th.join(path,r'test.csv'),index_col='Unnamed: 0')\", '#remove labels names from data\\ntrain=train.drop(...e\":\\n        test=test.drop(name, 1)\\n#train.head()', '# build a function vec_size which measures vecto...is=1)\\nvel_mean_test=np.mean(vel_mag_test, axis=1)', '#a function to calculate the acceleration betwee...test=np.mean(acc_df_test, axis=1)\\n#print (acc_df)', '#angle calculation\\ndef calc_angle(data,pos_index...+str(i)] =calc_angle2(data,i)\\n    return angle_df', 'angle_df_train=angle(train,1)\\nangle_df_test=angl...=np.mean(angle_df_test, axis=1)\\n#print (angle_df)', '#a df to calculate the change in angles between ...hange_df_test, axis=1)\\n#print (angle_change_mean)', '#count how many time steps each samples has (as ...)\\ntime_epoch_test = count_time(test) \\n#time_epoch', '#get goes_up and goes_down features:\\nup_and_down = create_go_up_and_go_down(train)', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', \"#uploading different packages- to remove the one...size'] = 12, 4\\n\\nfrom create_features \\nimport json\", \"#uploading different packages- to remove the one...ze'] = 12, 4\\n\\nimport create_features \\nimport json\", '#uploading different packages- to remove the one...\\nfrom Rafael.create_features import *\\nimport json', 'def create_go_up_and_go_down(table):\\n    up_and_...parabola_parameter_c\"] = params[2]\\n    return res', '#get goes_up and goes_down features:\\nup_and_down = create_go_up_and_go_down(train)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LeaveOneOut': <class 'sklearn.model_selection._split.LeaveOneOut'>, 'Out': {33: 0                                               ...258.844718\n2     ...\nLength: 28747, dtype: object, 38: 0                                               ...258.844718\n2     ...\nLength: 28747, dtype: object, 53:                        velX_0    velY_0      vel...                NaN  \n\n[28750 rows x 336 columns], 54: 0                                               ...2.736715\n2       ...\nLength: 28747, dtype: object, 61:        angle_mean\n0        8.617473\n1        2.7...25625\n28745   20.137023\n\n[28746 rows x 1 columns], 64:            velX_0    velY_0      velZ_0      vel...               6425  \n\n[28746 rows x 336 columns]}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'ShuffleSplit': <class 'sklearn.model_selection._split.ShuffleSplit'>, 'StratifiedKFold': <class 'sklearn.cross_validation.StratifiedKFold'>, ...}\n        self.user_ns = {'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', '#uploading different packages- to remove the one...2, 4\\n\\n#from create_features import *\\n#import json', \"#set path to imprt and save files from and in\\npa...th.join(path,r'test.csv'),index_col='Unnamed: 0')\", '#remove labels names from data\\ntrain=train.drop(...e\":\\n        test=test.drop(name, 1)\\n#train.head()', '# build a function vec_size which measures vecto...is=1)\\nvel_mean_test=np.mean(vel_mag_test, axis=1)', '#a function to calculate the acceleration betwee...test=np.mean(acc_df_test, axis=1)\\n#print (acc_df)', '#angle calculation\\ndef calc_angle(data,pos_index...+str(i)] =calc_angle2(data,i)\\n    return angle_df', 'angle_df_train=angle(train,1)\\nangle_df_test=angl...=np.mean(angle_df_test, axis=1)\\n#print (angle_df)', '#a df to calculate the change in angles between ...hange_df_test, axis=1)\\n#print (angle_change_mean)', '#count how many time steps each samples has (as ...)\\ntime_epoch_test = count_time(test) \\n#time_epoch', '#get goes_up and goes_down features:\\nup_and_down = create_go_up_and_go_down(train)', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', '#uploading different packages- to remove the one... 12, 4\\n\\nfrom create_features import *\\nimport json', \"#uploading different packages- to remove the one...size'] = 12, 4\\n\\nfrom create_features \\nimport json\", \"#uploading different packages- to remove the one...ze'] = 12, 4\\n\\nimport create_features \\nimport json\", '#uploading different packages- to remove the one...\\nfrom Rafael.create_features import *\\nimport json', 'def create_go_up_and_go_down(table):\\n    up_and_...parabola_parameter_c\"] = params[2]\\n    return res', '#get goes_up and goes_down features:\\nup_and_down = create_go_up_and_go_down(train)', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'LeaveOneOut': <class 'sklearn.model_selection._split.LeaveOneOut'>, 'Out': {33: 0                                               ...258.844718\n2     ...\nLength: 28747, dtype: object, 38: 0                                               ...258.844718\n2     ...\nLength: 28747, dtype: object, 53:                        velX_0    velY_0      vel...                NaN  \n\n[28750 rows x 336 columns], 54: 0                                               ...2.736715\n2       ...\nLength: 28747, dtype: object, 61:        angle_mean\n0        8.617473\n1        2.7...25625\n28745   20.137023\n\n[28746 rows x 1 columns], 64:            velX_0    velY_0      velZ_0      vel...               6425  \n\n[28746 rows x 336 columns]}, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'ShuffleSplit': <class 'sklearn.model_selection._split.ShuffleSplit'>, 'StratifiedKFold': <class 'sklearn.cross_validation.StratifiedKFold'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Yonathan\\<ipython-input-68-2974f718ea45> in <module>()\n     22 clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n     23                    cv=StratifiedKFold(y_train,n_folds=5, shuffle=True), \n     24                    scoring='f1_macro',\n     25                    verbose=10, refit=True)\n     26 \n---> 27 clf.fit(X_train, y_train)\n     28 \n     29 #trust your CV!\n     30 best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n     31 print('F1 score:', score)\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=sklearn.cross_validation.Stratif...obs', refit=True, scoring='f1_macro', verbose=10), X=           velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], y=array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64))\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...bs', refit=True, scoring='f1_macro', verbose=10)>\n        X =            velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns]\n        y = array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64)\n        self.param_grid = {'colsample_bytree': [0.7], 'learning_rate': [0.05], 'max_depth': [6], 'min_child_weight': [11], 'n_estimators': [5], 'nthread': [4], 'objective': ['multi:softmax'], 'seed': [1337], 'silent': [1], 'subsample': [0.8]}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=sklearn.cross_validation.Stratif...obs', refit=True, scoring='f1_macro', verbose=10), X=           velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], y=array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=5), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=5)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Oct 26 16:56:43 2017\nPID: 10132             Python 3.6.1: C:\\Users\\Yonathan\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8),            velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), make_scorer(f1_score, pos_label=None, average=macro), array([    0,     1,     2, ..., 19256, 19257, 19258]), array([   14,    16,    18, ..., 19244, 19245, 19249]), 10, {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 5, 'nthread': 4, 'objective': 'multi:softmax', 'seed': 1337, 'silent': 1, 'subsample': 0.8}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8),            velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), make_scorer(f1_score, pos_label=None, average=macro), array([    0,     1,     2, ..., 19256, 19257, 19258]), array([   14,    16,    18, ..., 19244, 19245, 19249]), 10, {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 5, 'nthread': 4, 'objective': 'multi:softmax', 'seed': 1337, 'silent': 1, 'subsample': 0.8}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8), X=           velX_0    velY_0      velZ_0      vel...               2631  \n\n[19259 rows x 335 columns], y=array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), scorer=make_scorer(f1_score, pos_label=None, average=macro), train=array([    0,     1,     2, ..., 19256, 19257, 19258]), test=array([   14,    16,    18, ..., 19244, 19245, 19249]), verbose=10, parameters={'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 11, 'n_estimators': 5, 'nthread': 4, 'objective': 'multi:softmax', 'seed': 1337, 'silent': 1, 'subsample': 0.8}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method XGBClassifier.fit of XGBClassifier...os_weight=1, seed=1337, silent=1, subsample=0.8)>\n        X_train =            velX_0    velY_0      velZ_0      vel...               2631  \n\n[15399 rows x 335 columns]\n        y_train = array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64)\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py in fit(self=XGBClassifier(base_score=0.5, colsample_bylevel=...pos_weight=1, seed=1337, silent=1, subsample=0.8), X=           velX_0    velY_0      velZ_0      vel...               2631  \n\n[15399 rows x 335 columns], y=array([ 3,  1, 12, ..., 21, 24,  1], dtype=int64), sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True)\n    434         if sample_weight is not None:\n    435             train_dmatrix = DMatrix(X, label=training_labels, weight=sample_weight,\n    436                                     missing=self.missing)\n    437         else:\n    438             train_dmatrix = DMatrix(X, label=training_labels,\n--> 439                                     missing=self.missing)\n        self.missing = nan\n    440 \n    441         self._Booster = train(xgb_options, train_dmatrix, self.n_estimators,\n    442                               evals=evals,\n    443                               early_stopping_rounds=early_stopping_rounds,\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in __init__(self=<xgboost.core.DMatrix object>, data=array([[  3.17416735e+02,  -2.45790805e+00,  -7....000000e+00,   0.00000000e+00,   2.63100000e+03]]), label=array([ 2,  0, 11, ..., 20, 23,  0], dtype=int64), missing=nan, weight=None, silent=False, feature_names=['velX_0', 'velY_0', 'velZ_0', 'velX_1', 'velY_1', 'velZ_1', 'velX_2', 'velY_2', 'velZ_2', 'velX_3', 'velY_3', 'velZ_3', 'velX_4', 'velY_4', 'velZ_4', 'velX_5', 'velY_5', 'velZ_5', 'velX_6', 'velY_6', ...], feature_types=['float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', 'float', ...])\n    275         if label is not None:\n    276             self.set_label(label)\n    277         if weight is not None:\n    278             self.set_weight(weight)\n    279 \n--> 280         self.feature_names = feature_names\n        self.feature_names = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', ...]\n        feature_names = ['velX_0', 'velY_0', 'velZ_0', 'velX_1', 'velY_1', 'velZ_1', 'velX_2', 'velY_2', 'velZ_2', 'velX_3', 'velY_3', 'velZ_3', 'velX_4', 'velY_4', 'velZ_4', 'velX_5', 'velY_5', 'velZ_5', 'velX_6', 'velY_6', ...]\n    281         self.feature_types = feature_types\n    282 \n    283     def _init_from_csr(self, csr):\n    284         \"\"\"\n\n...........................................................................\nC:\\Users\\Yonathan\\Anaconda3\\lib\\site-packages\\xgboost\\core.py in feature_names(self=<xgboost.core.DMatrix object>, feature_names=['velX_0', 'velY_0', 'velZ_0', 'velX_1', 'velY_1', 'velZ_1', 'velX_2', 'velY_2', 'velZ_2', 'velX_3', 'velY_3', 'velZ_3', 'velX_4', 'velY_4', 'velZ_4', 'velX_5', 'velY_5', 'velZ_5', 'velX_6', 'velY_6', ...])\n    566         if feature_names is not None:\n    567             # validate feature name\n    568             if not isinstance(feature_names, list):\n    569                 feature_names = list(feature_names)\n    570             if len(feature_names) != len(set(feature_names)):\n--> 571                 raise ValueError('feature_names must be unique')\n    572             if len(feature_names) != self.num_col():\n    573                 msg = 'feature_names must have the same length as data'\n    574                 raise ValueError(msg)\n    575             # prohibit to use symbols may affect to parse. e.g. []<\n\nValueError: feature_names must be unique\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "#brute force scan for all parameters, here are the tricks\n",
    "#usually max_depth is 6,7,8\n",
    "#learning rate is around 0.05, but small changes may make big diff\n",
    "#tuning min_child_weight subsample colsample_bytree can have \n",
    "#much fun of fighting against overfit \n",
    "#n_estimators is how many round of boosting\n",
    "#finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['multi:softmax'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "              'seed': [1337]}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=StratifiedKFold(y_train,n_folds=5, shuffle=True), \n",
    "                   scoring='f1_macro',\n",
    "                   verbose=10, refit=True)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#trust your CV!\n",
    "best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "print('F1 score:', score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a very simple XGboost model\n",
    "xg_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xg_test = xgb.DMatrix(X_test, label=y_test)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = 26\n",
    "param['min_child_weight']=1\n",
    "param['gamma']=0\n",
    "param['subsample']=1\n",
    "param['scale_pos_weight']=1\n",
    "param['colsample_bytree']=1\n",
    "param['learning_rate'] =0.1\n",
    "param['n_estimators']=1000\n",
    "param['seed']=123\n",
    "\n",
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 1000\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist )\n",
    "# get prediction\n",
    "pred = np.int_(bst.predict( xg_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculation\n",
    "f1 = f1_score(y_test, pred,average='macro')\n",
    "print(\"F1: %.2f%%\" % (f1 * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A simple Gradient boosting model\n",
    "train_gbdt=final_train.replace([np.inf],[np.nan])\n",
    "train_gbdt.fillna(0,inplace=True)\n",
    "y_gbdt=pd.DataFrame(train_gbdt['class'])\n",
    "X_gbdt=train_gbdt.drop('class', axis=1)\n",
    "\n",
    "ss = ShuffleSplit(n_splits=5,random_state=123345,test_size=0.2)\n",
    "for train_index, test_index in ss.split(X_gbdt,np.ravel(y_gbdt)): \n",
    "    X_train , X_test = X_gbdt.loc[train_index,:] , X_gbdt.loc[test_index,:]\n",
    "    y_train , y_test = y_gbdt.loc[train_index] , y_gbdt.loc[test_index]\n",
    "\n",
    "gbdt = GradientBoostingClassifier(max_depth=5,subsample=0.8,n_estimators=30)\n",
    "gbdt.fit(X_train,y_train)\n",
    "pred = gbdt.predict(X_test)\n",
    "print (classification_report(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_results = model.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(os.path.join(path,r'Rafael_submission1.csv'),header=True,index=True, index_label='id')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
